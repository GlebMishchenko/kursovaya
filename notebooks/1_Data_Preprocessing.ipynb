{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxraydwuCrMc"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --force-reinstall numpy pandas scipy\n",
        "!pip install catboost lightautoml autogluon --upgrade --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.figure as fgr\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler, RobustScaler, MaxAbsScaler, LabelEncoder, OneHotEncoder, PowerTransformer\n",
        "from sklearn.metrics import mean_squared_error,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
        "import pylab\n",
        "from scipy.stats import skew\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "GHAHGeVPCuKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Инициализация списков\n",
        "train_files = []\n",
        "test_files = []\n",
        "\n",
        "# Поиск файлов в текущей директории\n",
        "for filename in os.listdir('/content'):\n",
        "    if filename.endswith('-training.parquet'):\n",
        "        train_files.append(os.path.join('/content', filename))\n",
        "    elif filename.endswith('-testing.parquet'):\n",
        "        test_files.append(os.path.join('/content', filename))\n",
        "\n",
        "# Загрузка и объединение train-файлов\n",
        "train_df = pd.concat([pd.read_parquet(file) for file in train_files])\n",
        "\n",
        "# Загрузка и объединение test-файлов\n",
        "test_df = pd.concat([pd.read_parquet(file) for file in test_files])\n",
        "\n",
        "# Проверка размеров\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")"
      ],
      "metadata": {
        "id": "hp05SvIiCvuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "DcjZD6-ICw-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "VQoced94Czf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "5BUzfJeXC0eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
        "\n",
        "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
        "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
        "    cat_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
        "    cat_cols = cat_cols + num_but_cat\n",
        "    cat_cols = [col for col in cat_cols if col not in cat_but_cat]\n",
        "\n",
        "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
        "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
        "\n",
        "    print(f\"Observations: {dataframe.shape[0]}\")\n",
        "    print(f\"Variables: {dataframe.shape[1]}\")\n",
        "    print(f'cat_cols: {len(cat_cols)}')\n",
        "    print(f'num_cols: {len(num_cols)}')\n",
        "    print(f'cat_but_cat: {len(cat_but_cat)}')\n",
        "\n",
        "    return cat_cols, num_cols, cat_but_cat\n",
        "\n",
        "\n",
        "cat_cols, num_cols, cat_but_cat, = grab_col_names(train_df)\n",
        "cat_cols, num_cols, cat_but_cat"
      ],
      "metadata": {
        "id": "TY5irRhwC0sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cat_cols:\n",
        "    print(i, train_df[i].unique())"
      ],
      "metadata": {
        "id": "KiZi7GECC2dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_df.columns:\n",
        "    print(i, train_df[i].isnull().sum())"
      ],
      "metadata": {
        "id": "g8zOucDRC3fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_summary(dataframe, col_name, plot=False):\n",
        "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
        "                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
        "\n",
        "    if plot:\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(8, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
        "        plt.title(\"Frequency of \" + col_name)\n",
        "        plt.xticks(rotation=90)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        values = dataframe[col_name].value_counts()\n",
        "        plt.pie(x=values, labels=values.index, autopct=lambda p: '{:.2f}% ({:.0f})'.format(p, p/100 * sum(values)))\n",
        "        plt.title(\"Frequency of \" + col_name)\n",
        "        plt.legend(labels=['{} - {:.2f}%'.format(index, value/sum(values)*100) for index, value in zip(values.index, values)],\n",
        "                   loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=1)\n",
        "        plt.show(block=True)\n",
        "\n",
        "for col in cat_cols:\n",
        "    cat_summary(train_df, col, True)"
      ],
      "metadata": {
        "id": "UdbWq4UxC4Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_histplot(df, col, ax):\n",
        "    sns.histplot(df[col], kde=True, ax=ax)\n",
        "    ax.set_title(f'Histogram Plot of {col}')\n",
        "def my_distplot(df, col, ax):\n",
        "    sns.distplot(df[col], ax=ax)\n",
        "    ax.set_title(f'Distribution Plot of {col}')\n",
        "def my_kdeplot(df, col, ax):\n",
        "    sns.kdeplot(df[col], ax=ax, fill=True)\n",
        "    ax.set_title(f'KDE Plot of {col}')\n",
        "\n",
        "def my_scatterplot(df, col, ax):\n",
        "    sns.scatterplot(df[col], ax=ax)\n",
        "    ax.set_title(f'Scatter Plot of {col}')\n",
        "def my_lineplot(df, col, ax):\n",
        "    sns.lineplot(df[col], ax=ax)\n",
        "    ax.set_title(f'Line Plot of {col}')\n",
        "\n",
        "def my_pie_chart(df, col, ax):\n",
        "    labels = df[col].value_counts()\n",
        "    ax.pie(labels, labels=labels.index, autopct='%1.1f%%')\n",
        "    ax.set_title(f'Pie Chart of {col}')\n",
        "def my_countplot(df, col, ax):\n",
        "    sns.countplot(x=df[col], ax=ax)\n",
        "    ax.set_title(f'Count Plot of {col}')\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "def my_boxplot(df, col, ax):\n",
        "    sns.boxplot(y=df[col], ax=ax)\n",
        "def my_violinplot(df, col, ax):\n",
        "    sns.violinplot(y=df[col], ax=ax)\n",
        "\n",
        "def my_heatmap(df, size):\n",
        "    if size: plt.figure(figsize=size)\n",
        "    sns.heatmap(df.corr(), annot=True, fmt=\".1f\", cmap='Blues', annot_kws={\"size\": 12})\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.show()\n",
        "\n",
        "def my_vsplot(df, normal_col, label_col):\n",
        "    plt.figure(figsize=(10, 6), dpi=80)\n",
        "    plt.bar(list(dict(df[normal_col].value_counts()).keys()), dict(df[normal_col].value_counts()).values(), color='r')\n",
        "    plt.bar(list(dict(df[normal_col][df[label_col] == 1].value_counts()).keys()), dict(df[normal_col][df[label_col] == 1].value_counts()).values(), color='b')\n",
        "\n",
        "    plt.xlabel(normal_col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend(['All', label_col])\n",
        "\n",
        "def plot_charts_grid_single_feature(df, plot_func, size=(12, 4), n_col=1):\n",
        "    if len(df.columns) == 0:\n",
        "        return\n",
        "    n_rows = (len(df.columns) + n_col-1) // n_col\n",
        "    fig, axes = plt.subplots(n_rows, n_col, figsize=(size[0]*n_col, size[1]*n_rows))\n",
        "    if len(df.columns) == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, label in enumerate(df.columns):\n",
        "        plot_func(df, label, axes[i])\n",
        "        axes[i].set_xlabel(label)\n",
        "\n",
        "    for j in range(i+1, n_rows*n_col):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_-YV1YEpC6CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_charts_grid_single_feature(train_df[num_cols], my_distplot)"
      ],
      "metadata": {
        "id": "jZuH_bHGC7QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_charts_grid_single_feature(train_df[num_cols], my_boxplot, size=(2, 4), n_col=6)"
      ],
      "metadata": {
        "id": "DOvtl7QhC8UW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Label', y='Flow Duration', data=train_df)\n",
        "plt.title('Flow Duration Distribution for DDoS vs Normal Traffic')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='Protocol', y='Packet Length Mean', hue='Label', data=train_df)\n",
        "plt.title('Packet Length Mean by Protocol and Attack Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ot0z8t56C9YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag_columns = ['SYN Flag Count', 'ACK Flag Count', 'FIN Flag Count', 'RST Flag Count']\n",
        "\n",
        "for flag in flag_columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x=flag, hue='Label', data=train_df)\n",
        "    plt.title(f'{flag} Distribution by Attack Label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YZJALpXLC-bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_numeric_cols = len(train_df.select_dtypes(include=[np.number]).columns) // 3 * 2\n",
        "my_heatmap(train_df.select_dtypes(include=[np.number]), size=(n_numeric_cols+1, n_numeric_cols+1))"
      ],
      "metadata": {
        "id": "v6LOdt3UC_wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_cols = ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'FIN Flag Count', 'Fwd Avg Bytes/Bulk',\n",
        "'Fwd Avg Packets/Bulk',\n",
        "'Fwd Avg Bulk Rate',\n",
        "'Bwd Avg Bytes/Bulk',\n",
        "'Bwd Avg Packets/Bulk',\n",
        "'Bwd Avg Bulk Rate', 'ECE Flag Count', 'PSH Flag Count']"
      ],
      "metadata": {
        "id": "JfZF8d4bDBCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(remove_cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "rxE0LPVIDCCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_df = train_df.select_dtypes(include=[np.number])\n",
        "\n",
        "corr_matrix = numerical_df.corr().abs()\n",
        "\n",
        "mask = np.triu(np.ones(corr_matrix.shape), k=1) == 1\n",
        "\n",
        "upper_tri = corr_matrix.where(mask)\n",
        "\n",
        "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
        "\n",
        "numerical_df.drop(to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "e2In3W3UDC-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop"
      ],
      "metadata": {
        "id": "pzEkN1h1DD6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_col1 = ['Bwd Packets Length Total',\n",
        " 'Fwd Packet Length Mean',\n",
        " 'Bwd Packet Length Mean',\n",
        " 'Bwd Packet Length Std',\n",
        " 'Flow IAT Std',\n",
        " 'Flow IAT Max',\n",
        " 'Fwd IAT Total',\n",
        " 'Fwd IAT Mean',\n",
        " 'Fwd IAT Std',\n",
        " 'Fwd IAT Max',\n",
        " 'Fwd IAT Min',\n",
        " 'Bwd IAT Std',\n",
        " 'Bwd IAT Max',\n",
        " 'Fwd Packets/s',\n",
        " 'Packet Length Min',\n",
        " 'Packet Length Max',\n",
        " 'Packet Length Mean',\n",
        " 'Packet Length Std',\n",
        " 'Packet Length Variance',\n",
        " 'RST Flag Count',\n",
        " 'Avg Packet Size',\n",
        " 'Avg Fwd Segment Size',\n",
        " 'Avg Bwd Segment Size',\n",
        " 'Subflow Fwd Packets',\n",
        " 'Subflow Fwd Bytes',\n",
        " 'Subflow Bwd Packets',\n",
        " 'Subflow Bwd Bytes',\n",
        " 'Fwd Act Data Packets',\n",
        " 'Fwd Seg Size Min',\n",
        " 'Active Max',\n",
        " 'Active Min',\n",
        " 'Idle Mean',\n",
        " 'Idle Max',\n",
        " 'Idle Min']"
      ],
      "metadata": {
        "id": "dr3iCSE_DEl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(remove_col1, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "44YNXg-8DGEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_numeric_cols = len(train_df.select_dtypes(include=[np.number]).columns) // 3 * 2\n",
        "my_heatmap(train_df.select_dtypes(include=[np.number]), size=(n_numeric_cols+1, n_numeric_cols+1))"
      ],
      "metadata": {
        "id": "q5A2kzJJDG6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "j4W1N0JiDHv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "LbMX6nQUDIpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка размеров\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")"
      ],
      "metadata": {
        "id": "ljNSVyPDDJvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_columns = train_df.columns.intersection(test_df.columns)\n",
        "test_df = test_df[common_columns]"
      ],
      "metadata": {
        "id": "XoD9ZIn6DKvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "yVAXaJe_DLjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "id": "1AsvXRcBDMWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь для группировки меток test_df\n",
        "label_mapping_test = {\n",
        "    'DrDoS_UDP': 'UDP',\n",
        "    'DrDoS_LDAP': 'LDAP',\n",
        "    'DrDoS_MSSQL': 'MSSQL',\n",
        "    'DrDoS_NetBIOS': 'NetBIOS',\n",
        "    'DrDoS_SNMP': 'UDP',  # SNMP использует UDP\n",
        "    'DrDoS_DNS': 'UDP',   # DNS обычно через UDP\n",
        "    'DrDoS_NTP': 'UDP',   # NTP-атаки через UDP\n",
        "    'UDP-lag': 'UDPLag',\n",
        "    'WebDDoS': 'Syn',     # WebDDoS часто использует SYN-флуд\n",
        "    'TFTP': 'UDP',        # TFTP работает по UDP\n",
        "    'Benign': 'Benign',\n",
        "    'Syn': 'Syn'\n",
        "}\n",
        "\n",
        "# Применяем преобразование к test_df\n",
        "test_df['Label'] = test_df['Label'].map(label_mapping_test)"
      ],
      "metadata": {
        "id": "-ThelLDqDNDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_train_labels = train_df['Label'].unique()\n",
        "unique_test_labels = test_df['Label'].unique()\n",
        "\n",
        "unknown_labels = set(unique_test_labels) - set(unique_train_labels)\n",
        "assert not unknown_labels, f\"Тестовая выборка содержит неизвестные классы: {unknown_labels}\""
      ],
      "metadata": {
        "id": "alCBJsVgDOGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df[\"Label\"] != \"Portmap\"]"
      ],
      "metadata": {
        "id": "JgWWm-g9DPY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Label'].unique()"
      ],
      "metadata": {
        "id": "YamdnWiIDQH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Label'].unique()"
      ],
      "metadata": {
        "id": "Z3v0erlDDQwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Для train_df\n",
        "train_class_distribution = train_df['Label'].value_counts().sort_values(ascending=False)\n",
        "print(\"Распределение классов в train_df:\\n\", train_class_distribution)\n",
        "\n",
        "# Для test_df\n",
        "test_class_distribution = test_df['Label'].value_counts().sort_values(ascending=False)\n",
        "print(\"\\nРаспределение классов в test_df:\\n\", test_class_distribution)"
      ],
      "metadata": {
        "id": "G6NPlXiYDReq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "train_df['Label'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.title(\"Распределение классов в train_df\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g83_RxNNDS4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "test_df['Label'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.title(\"Распределение классов в test_df\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UN4BWwi4DT5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "train_class_distribution.plot(kind='bar')\n",
        "plt.title(\"Train dataset\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "test_class_distribution.plot(kind='bar')\n",
        "plt.title(\"Test dataset\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qdw6Kx-WDVAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_class_count = train_class_distribution.max()\n",
        "min_class_count = train_class_distribution.min()\n",
        "imbalance_ratio = max_class_count / min_class_count\n",
        "\n",
        "print(f\"\\nКоэффициент дисбаланса: {imbalance_ratio:.2f}\")"
      ],
      "metadata": {
        "id": "o3_sbjzfDV56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Объединяем исходные данные\n",
        "full_data = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# 2. Стратифицированное разделение\n",
        "train_df_new, test_df_new = train_test_split(\n",
        "    full_data,\n",
        "    test_size=0.2,\n",
        "    stratify=full_data['Label'],  # Стратификация по оригинальным меткам\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3. Теперь ПЕРЕЗАПИСЫВАЕМ оригинальные данные\n",
        "train_df = train_df_new.copy()\n",
        "test_df = test_df_new.copy()\n",
        "\n",
        "# 4. Кодируем метки в числовой формат (уже в новых данных)\n",
        "le = LabelEncoder()\n",
        "train_df['Label_encoded'] = le.fit_transform(train_df['Label'])\n",
        "test_df['Label_encoded'] = le.transform(test_df['Label'])\n",
        "\n",
        "# Проверяем распределение\n",
        "print(\"Train распределение:\\n\", train_df['Label'].value_counts())\n",
        "print(\"\\nTest распределение:\\n\", test_df['Label'].value_counts())\n",
        "\n",
        "# Проверяем соответствие\n",
        "label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "print(\"Соответствие меток и чисел:\\n\", label_mapping)"
      ],
      "metadata": {
        "id": "njOdHx0QDW4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}