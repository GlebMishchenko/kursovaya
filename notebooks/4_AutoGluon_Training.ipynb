{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Загрузка данных\n",
        "train_df = pd.read_csv('data/processed/train_data.csv')\n",
        "test_df = pd.read_csv('data/processed/test_data.csv')\n",
        "\n",
        "# Проверка загрузки\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "print(\"\\nПервые 3 строки train_df:\")\n",
        "print(train_df.head(3))\n"
      ],
      "metadata": {
        "id": "4nCtFCEkEyNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaFqwIydCj-_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from collections import Counter\n",
        "\n",
        "### 1. Подготовка данных ###\n",
        "def prepare_data(train_df, test_df):\n",
        "    \"\"\"Подготовка данных с одинаковым набором признаков\"\"\"\n",
        "    # Удаляем лишние колонки если они есть\n",
        "    for df in [train_df, test_df]:\n",
        "        if 'is_attack' in df.columns:\n",
        "            df.drop('is_attack', axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "    # Объединяем редкие классы\n",
        "    rare_classes = ['NetBIOS', 'LDAP']\n",
        "    train_df['Label'] = train_df['Label'].replace({k: 'RARE' for k in rare_classes})\n",
        "    test_df['Label'] = test_df['Label'].replace({k: 'RARE' for k in rare_classes})\n",
        "\n",
        "    # Фиксируем кодировщик\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train_df['Label'])\n",
        "\n",
        "    # Кодируем метки\n",
        "    train_df['Label_encoded'] = le.transform(train_df['Label'])\n",
        "    test_df['Label_encoded'] = le.transform(test_df['Label'])\n",
        "\n",
        "    return train_df, test_df, le\n",
        "\n",
        "### 2. Балансировка данных ###\n",
        "def balance_data(train_df, le):\n",
        "    \"\"\"Балансировка с гарантией одинаковых признаков\"\"\"\n",
        "    features = train_df.drop(['Label', 'Label_encoded'], axis=1).columns\n",
        "    X = train_df[features]\n",
        "    y = train_df['Label_encoded']\n",
        "\n",
        "    class_counts = Counter(y)\n",
        "    strategy = {\n",
        "        cls: min(count * 2, 50000)\n",
        "        for cls, count in class_counts.items()\n",
        "        if count < 30000\n",
        "    }\n",
        "\n",
        "    if strategy:\n",
        "        smote = SMOTE(sampling_strategy=strategy, k_neighbors=3)\n",
        "        X, y = smote.fit_resample(X, y)\n",
        "\n",
        "    balanced_data = pd.DataFrame(X)\n",
        "    balanced_data['Label_encoded'] = y\n",
        "    return balanced_data\n",
        "\n",
        "### 3. Обучение AutoGluon ###\n",
        "def train_autogluon(train_data, time_limit=3600):\n",
        "    \"\"\"Настройка и обучение AutoGluon\"\"\"\n",
        "    predictor = TabularPredictor(\n",
        "        label='Label_encoded',\n",
        "        problem_type='multiclass',\n",
        "        eval_metric='f1_weighted'\n",
        "    ).fit(\n",
        "        train_data,\n",
        "        presets='best_quality',\n",
        "        time_limit=time_limit,\n",
        "        hyperparameters={\n",
        "            'GBM': [\n",
        "                {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
        "                {},\n",
        "            ],\n",
        "            'CAT': {},\n",
        "            'XGB': {},\n",
        "            'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini'}}],\n",
        "        }\n",
        "    )\n",
        "    return predictor\n",
        "\n",
        "### 4. Основной пайплайн ###\n",
        "def autogluon_pipeline(train_df, test_df, time_limit=3600):\n",
        "    # 1. Подготовка данных\n",
        "    train_df, test_df, le = prepare_data(train_df, test_df)\n",
        "\n",
        "    # 2. Балансировка\n",
        "    balanced_train = balance_data(train_df, le)\n",
        "\n",
        "    # 3. Обучение\n",
        "    predictor = train_autogluon(balanced_train, time_limit)\n",
        "\n",
        "    # 4. Предсказание\n",
        "    X_test = test_df.drop(['Label', 'Label_encoded'], axis=1, errors='ignore')\n",
        "    y_test = test_df['Label_encoded']\n",
        "    y_pred = predictor.predict(X_test)\n",
        "\n",
        "    # 5. Отчет\n",
        "    print(\"Лучшие модели:\")\n",
        "    print(predictor.leaderboard())\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(predictor.evaluate_predictions(\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred,\n",
        "        auxiliary_metrics=True\n",
        "    ))\n",
        "\n",
        "    return predictor, le\n",
        "\n",
        "### Запуск ###\n",
        "predictor, label_encoder = autogluon_pipeline(train_df.copy(), test_df.copy(), time_limit=3600)"
      ]
    }
  ]
}